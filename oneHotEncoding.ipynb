{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oneHotEncoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4LzxfjG+EBGYHQaCo07Gu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samp3209/datamining/blob/main/oneHotEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "ptJJFBWTsm7p",
        "outputId": "92ad9e46-84cd-4682-d88a-a11ad9ad9043"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import linear_model as lm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "university_towns = []\n",
        "\n",
        "with open('university_towns.txt') as file:\n",
        "  for line in file:\n",
        "    if '[edit]' in line:\n",
        "      state = line\n",
        "    else:\n",
        "      university_towns.append((state,line))\n",
        "\n",
        "university_towns[:5]\n",
        "\n",
        "df = pd.DataFrame(university_towns, columns=['State', 'RegionName'])\n",
        "#print(df.head())\n",
        "df['State'] = df['State'].str.replace('\\[edit\\]\\\\n', ' ')\n",
        "\n",
        "def get_city(item):\n",
        "  #takes in df and goes line by line editing the data by finding where a given character is a choosing everything before that character\n",
        "    if ')' in item:\n",
        "      return item[:item.find(')')]\n",
        "    elif '[' in item:\n",
        "      return item[:item.find('[')]\n",
        "    else:\n",
        "      return item\n",
        "\n",
        "df = df.applymap(get_city)\n",
        "df.head()\n",
        "#splits the regionname column into city and university and cleaning the columns up\n",
        "df[['City', 'University', 'misc']] = df['RegionName'].str.split(\"\\(\", expand=True)\n",
        "df.drop('misc', axis=1, inplace=True)\n",
        "df.drop('RegionName', axis=1, inplace=True)\n",
        "df = df.dropna()\n",
        "label_df = df\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "#print(df.dtypes)\n",
        "data_coloumn_category = df.select_dtypes(exclude=[np.number]).columns\n",
        "data_column_numeric = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "#print(data_coloumn_category)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encoded = onehot_encoder.fit_transform(df[['City', 'University']])\n",
        "\n",
        "#creating final dataset. Problem is that there are so many states and cities its difficult to use onehot\n",
        "onehot_encoded_frame = pd.DataFrame(onehot_encoded, columns = onehot_encoder.get_feature_names(['City','University']))\n",
        "#df_onehot_getdummies = pd.get_dummies(df[data_coloumn_category], prefix=data_coloumn_category)\n",
        "#final_df = pd.concat([df_onehot_getdummies, df[data_column_numeric]], axis=1)\n",
        "#final_df.std().sort_values(ascending=False)\n",
        "#onehot_encoded_frame.std().sort_values(ascending=False)\n",
        "print(onehot_encoded_frame.shape)\n",
        "\n",
        "\n",
        "\n",
        "#scaler = MinMaxScaler()\n",
        "#label encoding the dataset into new df called label_df\n",
        "\n",
        "label_df['State'] = label_encoder.fit_transform(df['State'])\n",
        "\n",
        "#label_df = sklearn.preprocessing.minmax_scale(label_df)\n",
        "#scaling each of the columns using min max scaler\n",
        "#label_df['University'] = sklearn.preprocessing.minmax_scale(label_df['University'])\n",
        "label_df['State'] = sklearn.preprocessing.minmax_scale(label_df['State'])\n",
        "#label_df['City'] = sklearn.preprocessing.minmax_scale(label_df['City'])\n",
        "print(label_df.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#splitting data into testing/training data sets and reshaping data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(onehot_encoded_frame,label_df['State'], test_size=.25)\n",
        "xb = np.array(X_train)\n",
        "xb = xb.reshape(-1,1)\n",
        "yb = np.array(Y_train)\n",
        "yb = yb.reshape(-1,1)\n",
        "\n",
        "xb_test = np.array(X_test)\n",
        "xb_test = xb.reshape(-1,1)\n",
        "yb_test = np.array(Y_test)\n",
        "yb_test = yb.reshape(-1,1)\n",
        "\n",
        "#generating best model and getting its score\n",
        "bestModel = lm.LinearRegression().fit(xb,yb)\n",
        "BMscore = bestModel.score(xb_test, yb_test)\n",
        "print(BMscore)\n",
        "yb_pred = bestModel.predict(xb_test)\n",
        "#plotting the model\n",
        "plt.figure(0)\n",
        "plt.scatter(xb_test, yb_test)\n",
        "plt.plot(xb_test, yb_pred, color='red')\n",
        "\n",
        "#final thoughts: The data does not have any strong linearity after testing out all of the features. This data cannot be accurately predicted with linear regression."
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(513, 997)\n",
            "(513, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-66eeb1eed453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#generating best model and getting its score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mbestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mBMscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBMscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 492\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [382848, 384]"
          ]
        }
      ]
    }
  ]
}