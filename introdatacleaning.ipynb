{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introdatacleaning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhenbXk++HXzZWAOup4hGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samp3209/datamining/blob/main/introdatacleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSgA4zdqFX5e",
        "outputId": "287f920e-2968-4e48-ac72-00273740424a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('flickr.csv')\n",
        "#finding columns to remove based on how many NaNs there are\n",
        "#data['Edition Statement'].isna().value_counts()/len(data)\n",
        "#data['Corporate Author'].isna().value_counts()/len(data)\n",
        "#data['Engraver'].isna().value_counts()/len(data)\n",
        "#data['Former owner'].isna().value_counts()/len(data)\n",
        "\n",
        "to_drop = ['Edition Statement', 'Corporate Author', 'Corporate Contributors', 'Former owner', 'Engraver']\n",
        "data2 = data.drop(columns=to_drop)\n",
        "data2\n",
        "#check for unique values\n",
        "data2['Identifier'].value_counts().describe()\n",
        "data2['Date of Publication'].is_unique\n",
        "#seting identifier to index\n",
        "data2.set_index('Identifier', inplace=True)\n",
        "data2.loc[206]\n",
        "\n",
        "#fixing date of publication column using regex\n",
        "data2.loc[1905:, 'Date of Publication'].head(10)\n",
        "regex = r'^(\\d{4})'\n",
        "dataextract = data2['Date of Publication'].str.extract(regex, expand=False)\n",
        "dataextract\n",
        "data2['Date of Publication'] = pd.to_numeric(dataextract)\n",
        "#data2.dtypes\n",
        "data2['Date of Publication'].describe()\n",
        "data2['Date of Publication'].std()/data2['Date of Publication'].mean()\n",
        "\n",
        "#looking at place of publication column getting rid of junk excess vocab to shorten to just London or Paris\n",
        "#data2['Place of Publication'].value_counts()\n",
        "list = data2['Place of Publication']\n",
        "london = list.str.contains('London')\n",
        "Paris = list.str.contains('Paris')\n",
        "data2['Place of Publication'] = np.where(london, 'London',\n",
        "         np.where(Paris, 'Paris',\n",
        "                  list.str.replace('-', ' ')))\n",
        "data2['Place of Publication']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Identifier\n",
              "206                     London\n",
              "216                     London\n",
              "218                     London\n",
              "472                     London\n",
              "480                     London\n",
              "                  ...         \n",
              "4158088                 London\n",
              "4158128                  Derby\n",
              "4159563                 London\n",
              "4159587    Newcastle upon Tyne\n",
              "4160339                 London\n",
              "Name: Place of Publication, Length: 8287, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}